{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sampled_x_train.csv\")  # Randomized sample of the big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>piezo_station_department_code</th>\n",
       "      <th>piezo_station_update_date</th>\n",
       "      <th>piezo_station_investigation_depth</th>\n",
       "      <th>piezo_station_altitude</th>\n",
       "      <th>piezo_station_bss_code</th>\n",
       "      <th>piezo_station_longitude</th>\n",
       "      <th>piezo_station_latitude</th>\n",
       "      <th>piezo_station_bss_id</th>\n",
       "      <th>piezo_measurement_date</th>\n",
       "      <th>...</th>\n",
       "      <th>prelev_longitude_2</th>\n",
       "      <th>prelev_latitude_2</th>\n",
       "      <th>prelev_commune_code_insee_2</th>\n",
       "      <th>prelev_other_volume_sum</th>\n",
       "      <th>insee_%_agri</th>\n",
       "      <th>insee_pop_commune</th>\n",
       "      <th>insee_med_living_level</th>\n",
       "      <th>insee_%_ind</th>\n",
       "      <th>insee_%_const</th>\n",
       "      <th>piezo_groundwater_level_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>951052</td>\n",
       "      <td>02</td>\n",
       "      <td>Fri Jun 28 07:31:38 CEST 2024</td>\n",
       "      <td>28.20</td>\n",
       "      <td>102.00</td>\n",
       "      <td>00843X0024/S1</td>\n",
       "      <td>3.854086</td>\n",
       "      <td>49.669113</td>\n",
       "      <td>BSS000FWXT</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>...</td>\n",
       "      <td>3.963568</td>\n",
       "      <td>49.766516</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>10611661.0</td>\n",
       "      <td>0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>20470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1070593</td>\n",
       "      <td>24</td>\n",
       "      <td>Fri Jun 28 07:31:38 CEST 2024</td>\n",
       "      <td>350.00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>07574X0014/F</td>\n",
       "      <td>0.313916</td>\n",
       "      <td>45.309031</td>\n",
       "      <td>BSS001WCPB</td>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415768</td>\n",
       "      <td>45.404920</td>\n",
       "      <td>24199.0</td>\n",
       "      <td>9837160.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>528.0</td>\n",
       "      <td>23880</td>\n",
       "      <td>2.7</td>\n",
       "      <td>51.4</td>\n",
       "      <td>Very High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2044217</td>\n",
       "      <td>37</td>\n",
       "      <td>Fri Jun 28 07:31:38 CEST 2024</td>\n",
       "      <td>14.46</td>\n",
       "      <td>96.62</td>\n",
       "      <td>04571X0015/P</td>\n",
       "      <td>0.416863</td>\n",
       "      <td>47.514282</td>\n",
       "      <td>BSS001FFSN</td>\n",
       "      <td>2022-02-12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353886</td>\n",
       "      <td>47.347719</td>\n",
       "      <td>37123.0</td>\n",
       "      <td>13871887.0</td>\n",
       "      <td>5</td>\n",
       "      <td>914.0</td>\n",
       "      <td>22900</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3023095</td>\n",
       "      <td>46</td>\n",
       "      <td>Fri Jun 28 07:31:38 CEST 2024</td>\n",
       "      <td>42.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>08565X0007/F</td>\n",
       "      <td>1.086858</td>\n",
       "      <td>44.490808</td>\n",
       "      <td>BSS002AJSB</td>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.9</td>\n",
       "      <td>340.0</td>\n",
       "      <td>24280</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>Very Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1437526</td>\n",
       "      <td>47</td>\n",
       "      <td>Wed May 08 07:03:22 CEST 2024</td>\n",
       "      <td>7.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>09021X0170/PUITS</td>\n",
       "      <td>0.445087</td>\n",
       "      <td>44.229290</td>\n",
       "      <td>BSS002CAXB</td>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340154</td>\n",
       "      <td>44.133873</td>\n",
       "      <td>47195.0</td>\n",
       "      <td>29267743.0</td>\n",
       "      <td>40.8</td>\n",
       "      <td>755.0</td>\n",
       "      <td>22610</td>\n",
       "      <td>12.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index piezo_station_department_code      piezo_station_update_date  \\\n",
       "0     951052                            02  Fri Jun 28 07:31:38 CEST 2024   \n",
       "1    1070593                            24  Fri Jun 28 07:31:38 CEST 2024   \n",
       "2    2044217                            37  Fri Jun 28 07:31:38 CEST 2024   \n",
       "3    3023095                            46  Fri Jun 28 07:31:38 CEST 2024   \n",
       "4    1437526                            47  Wed May 08 07:03:22 CEST 2024   \n",
       "\n",
       "   piezo_station_investigation_depth  piezo_station_altitude  \\\n",
       "0                              28.20                  102.00   \n",
       "1                             350.00                   66.00   \n",
       "2                              14.46                   96.62   \n",
       "3                              42.00                   90.00   \n",
       "4                               7.00                   39.00   \n",
       "\n",
       "  piezo_station_bss_code  piezo_station_longitude  piezo_station_latitude  \\\n",
       "0          00843X0024/S1                 3.854086               49.669113   \n",
       "1           07574X0014/F                 0.313916               45.309031   \n",
       "2           04571X0015/P                 0.416863               47.514282   \n",
       "3           08565X0007/F                 1.086858               44.490808   \n",
       "4       09021X0170/PUITS                 0.445087               44.229290   \n",
       "\n",
       "  piezo_station_bss_id piezo_measurement_date  ... prelev_longitude_2  \\\n",
       "0           BSS000FWXT             2020-12-28  ...           3.963568   \n",
       "1           BSS001WCPB             2021-02-11  ...           0.415768   \n",
       "2           BSS001FFSN             2022-02-12  ...           0.353886   \n",
       "3           BSS002AJSB             2023-02-17  ...                NaN   \n",
       "4           BSS002CAXB             2021-06-29  ...           0.340154   \n",
       "\n",
       "  prelev_latitude_2 prelev_commune_code_insee_2  prelev_other_volume_sum  \\\n",
       "0         49.766516                      2116.0               10611661.0   \n",
       "1         45.404920                     24199.0                9837160.0   \n",
       "2         47.347719                     37123.0               13871887.0   \n",
       "3               NaN                         NaN                      NaN   \n",
       "4         44.133873                     47195.0               29267743.0   \n",
       "\n",
       "  insee_%_agri  insee_pop_commune insee_med_living_level  insee_%_ind  \\\n",
       "0            0              139.0                  20470            0   \n",
       "1         24.3              528.0                  23880          2.7   \n",
       "2            5              914.0                  22900            7   \n",
       "3         23.9              340.0                  24280          1.5   \n",
       "4         40.8              755.0                  22610         12.2   \n",
       "\n",
       "   insee_%_const  piezo_groundwater_level_category  \n",
       "0              0                               Low  \n",
       "1           51.4                         Very High  \n",
       "2             32                           Average  \n",
       "3            5.2                          Very Low  \n",
       "4            6.1                           Average  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning all redundant value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(\n",
    "    df: pd.DataFrame,\n",
    "    piezo: bool = False,\n",
    "    meteo: bool = False,\n",
    "    hydro: bool = False,\n",
    "    prelev: bool = False,\n",
    "    insee: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    # Define columns to exclude for each category\n",
    "    excluded_piezo = [\n",
    "        \"piezo_station_department_code\",\n",
    "        \"piezo_station_update_date\",\n",
    "        \"piezo_station_department_name\",\n",
    "        \"piezo_station_commune_code_insee\",\n",
    "        \"piezo_station_pe_label\",\n",
    "        \"piezo_station_bdlisa_codes\",\n",
    "        \"piezo_station_bss_code\",\n",
    "        \"piezo_station_commune_name\",\n",
    "        \"piezo_station_bss_id\",\n",
    "        \"piezo_bss_code\",\n",
    "        \"piezo_continuity_name\",\n",
    "        \"piezo_producer_code\",\n",
    "        \"piezo_producer_name\",\n",
    "        \"piezo_measure_nature_name\",\n",
    "    ]\n",
    "    excluded_meteo = [\"meteo_id\", \"meteo_radiation_IR\", \"meteo_name\"]\n",
    "    excluded_hydro = [\n",
    "        \"hydro_station_code\",\n",
    "        \"hydro_status_label\",\n",
    "        \"hydro_method_code\",\n",
    "        \"hydro_method_label\",\n",
    "        \"hydro_qualification_label\",\n",
    "    ]\n",
    "    excluded_prelev = [\n",
    "        \"prelev_structure_code_0\",\n",
    "        \"prelev_volume_0\",\n",
    "        \"prelev_usage_label_0\",\n",
    "        \"prelev_volume_obtention_mode_label_0\",\n",
    "        \"prelev_longitude_0\",\n",
    "        \"prelev_latitude_0\",\n",
    "        \"prelev_commune_code_insee_0\",\n",
    "        \"prelev_structure_code_1\",\n",
    "        \"prelev_volume_1\",\n",
    "        \"prelev_usage_label_1\",\n",
    "        \"prelev_volume_obtention_mode_label_1\",\n",
    "        \"prelev_longitude_1\",\n",
    "        \"prelev_latitude_1\",\n",
    "        \"prelev_commune_code_insee_1\",\n",
    "        \"prelev_structure_code_2\",\n",
    "        \"prelev_volume_2\",\n",
    "        \"prelev_usage_label_2\",\n",
    "        \"prelev_volume_obtention_mode_label_2\",\n",
    "        \"prelev_longitude_2\",\n",
    "        \"prelev_latitude_2\",\n",
    "        \"prelev_commune_code_insee_2\",\n",
    "        \"prelev_other_volume_sum\",\n",
    "    ]\n",
    "    excluded_insee = [\n",
    "        \"prelev_commune_code_insee_0\",\n",
    "        \"prelev_commune_code_insee_1\",\n",
    "        \"prelev_commune_code_insee_2\",\n",
    "        \"insee_%_agri\",\n",
    "        \"insee_pop_commune\",\n",
    "        \"insee_med_living_level\",\n",
    "        \"insee_%_ind\",\n",
    "        \"insee_%_const\",\n",
    "    ]\n",
    "    # Combine columns to drop based on the parameters\n",
    "    columns_to_drop = []\n",
    "    if piezo:\n",
    "        columns_to_drop += excluded_piezo\n",
    "    if meteo:\n",
    "        columns_to_drop += excluded_meteo\n",
    "    if hydro:\n",
    "        columns_to_drop += excluded_hydro\n",
    "    if prelev:\n",
    "        columns_to_drop += excluded_prelev\n",
    "    if insee:\n",
    "        columns_to_drop += excluded_insee\n",
    "\n",
    "    # Drop columns safely (ignore errors for missing columns)\n",
    "\n",
    "    df_filtered = df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unifies longitude and latitude columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_long_lat(df: pd.DataFrame, distance_threshold: int = 25) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Unifies longitude and latitude into single columns if distance_piezo_hydro is below the threshold.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        distance_threshold (int): The maximum distance for unification.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The modified DataFrame with unified longitude and latitude columns.\n",
    "    \"\"\"\n",
    "    # Columns to exclude after processing\n",
    "    excluding = [\n",
    "        \"piezo_station_latitude\",\n",
    "        \"piezo_station_longitude\",\n",
    "        \"hydro_longitude\",\n",
    "        \"hydro_latitude\",\n",
    "        \"meteo_longitude\",\n",
    "        \"meteo_latitude\",\n",
    "        \"distance_piezo_hydro\",\n",
    "        \"distance_hydro_meteo\",\n",
    "    ]\n",
    "\n",
    "    # Ensure the required column exists\n",
    "    if \"distance_piezo_hydro\" in df.columns:\n",
    "        # Create unified longitude and latitude where condition is met\n",
    "        df.loc[df[\"distance_piezo_hydro\"] < distance_threshold, \"longitude\"] = df[\n",
    "            \"piezo_station_longitude\"\n",
    "        ]\n",
    "        df.loc[df[\"distance_piezo_hydro\"] < distance_threshold, \"latitude\"] = df[\n",
    "            \"piezo_station_latitude\"\n",
    "        ]\n",
    "\n",
    "    # Drop the excluded columns\n",
    "    df = df.drop(columns=excluding, errors=\"ignore\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unify date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_date(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Unifies date combine date in a single column.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The modified DataFrame with unifies dates columns.\n",
    "    \"\"\"\n",
    "    # Columns to exclude after processing\n",
    "    excluding = [\"piezo_measurement_date\", \"meteo_date\", \"hydro_observation_date_elab\"]\n",
    "\n",
    "    # Check and assign the first available date column\n",
    "    if \"piezo_measurement_date\" in df.columns:\n",
    "        df[\"date\"] = df[\"piezo_measurement_date\"]\n",
    "\n",
    "    df = df.drop(columns=excluding, errors=\"ignore\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning residual empty value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_essential_data(df: pd.DataFrame, threshold: float = 0.8) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Keeping essential data by removing columns with less than thrshold % of empty data\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "\n",
    "        threshold (float): % of empty data in a column\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute threshold % not null value for each columns\n",
    "    non_null_percentage = df.notnull().mean()  # not null values %\n",
    "\n",
    "    # Select only column with less 80 % not null values\n",
    "    columns_to_keep = non_null_percentage[non_null_percentage >= threshold].index\n",
    "    filtered_df = df[columns_to_keep]\n",
    "\n",
    "    # Print datasat after filtration\n",
    "    print(\"Initals columns :\", df.columns.tolist())\n",
    "    print(\"Keeped columns :\", filtered_df.columns.tolist())\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning piezzo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piezzo_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocesses the DataFrame by applying a series of cleaning and transformation steps for piezzo data.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The preprocessed DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Replace NaN in qualification columns\n",
    "    df[\"piezo_qualification\"] = df[\"piezo_qualification\"].fillna(\"Incertaine\")\n",
    "\n",
    "    # Replace NaN in piezo_measure_nature_code\n",
    "    df[\"piezo_measure_nature_code\"] = df[\"piezo_measure_nature_code\"].fillna(0)\n",
    "\n",
    "    # Replace NaN in piezo_obtention_mode\n",
    "    df[\"piezo_obtention_mode\"] = df[\"piezo_obtention_mode\"].fillna(\n",
    "        \"Mode d'obtention inconnu\"\n",
    "    )\n",
    "\n",
    "    # Replace NaN in piezo_status\n",
    "    df[\"piezo_status\"] = df[\"piezo_status\"].fillna(\"Donnée brute\")\n",
    "\n",
    "    # Define a mapping for the labels to integers\n",
    "    qualification_label_mapping = {\n",
    "        \"Correcte\": 3,\n",
    "        \"Non qualifié\": 2,\n",
    "        \"Incorrecte\": 0,\n",
    "        \"Incertaine\": 1,\n",
    "    }\n",
    "\n",
    "    # Map the labels to integers\n",
    "    df[\"piezo_qualification\"] = df[\"piezo_qualification\"].map(\n",
    "        qualification_label_mapping\n",
    "    )\n",
    "\n",
    "    # Mapping obtention mode\n",
    "    elements = [\"piezo_status\", \"piezo_obtention_mode\"]\n",
    "    df = pd.get_dummies(df, columns=elements, drop_first=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling others NaN values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faiss_imputer import FaissImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "def impute_na(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Impute missing values in a DataFrame using FaissImputer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame with missing values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The DataFrame with missing values imputed.\n",
    "    \"\"\"\n",
    "    # Drop non-numerical columns\n",
    "    categorical_cols = df.select_dtypes(include=[\"object\", \"datetime64\"]).columns\n",
    "    df = df.drop(columns=categorical_cols)\n",
    "\n",
    "    # Create an instance of FaissImputer\n",
    "    imputer = FaissImputer(n_neighbors=10)\n",
    "    simple_imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "    # Fit the imputer on the data frame with missing values\n",
    "    imputer.fit(df)\n",
    "\n",
    "    # Transform the data frame with missing values\n",
    "    df = pd.DataFrame(imputer.transform(df), columns=df.columns)\n",
    "    df = pd.DataFrame(simple_imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def date_to_timestamp_convertion(df:pd.DataFrame):\n",
    "    # Convert the date column to datetime and then to a timestamp\n",
    "    df['date'] = pd.to_datetime(df['date'], format=\"%Y-%m-%d\", errors='coerce').astype(int) // 10**9\n",
    "    \n",
    "    # Normalize for better scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    df['date'] = scaler.fit_transform(df[['timestamp']])\n",
    "\n",
    "    return df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocesses the DataFrame by applying a series of cleaning and transformation steps.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        cleaning_params (dict): Dictionary of parameters for the `cleaning` function.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The preprocessed DataFrame.\n",
    "    \"\"\"\n",
    "    df = cleaning(df, True, True, True, True, True)\n",
    "    df = unify_long_lat(df)\n",
    "    df = unify_date(df)\n",
    "    df = date_to_timestamp_convertion(df)\n",
    "    df = impute_na(df)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
